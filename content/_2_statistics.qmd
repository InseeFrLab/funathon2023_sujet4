# 2️⃣ Faire des statistiques agrégées par catégories

Cette partie permet de calculer en amont de l'application des
statistiques descriptives qui pourront être utilisées
par celle-ci. 

Il est préférable de minimiser la quantité de calculs
faits à la volée dans le cadre d'une application. Sinon,
le risque est une latence embêtante pour l'utilisateur
voire un crash du serveur à cause de besoins
de ressources trop importants.

Cette partie propose ainsi de créer en avance une
base de données synthétisant 
le
nombre de produits dans une catégorie donnée (par exemple les
fromages à pâte crue) qui partagent la même note.
Cela nous permettra d'afficher des statistiques personnalisées
sur les produits similaires à celui qu'on scanne. 


## 2.1. Préliminaires (🟡,🟢,🔵,🔴,⚫)


Sur le plan technique, cette partie propose deux cadres de manipulation
de données différents,
selon le balisage de la voie:

- 🟡,🟢,🔵: utilisation de `Pandas`
- 🔴,⚫: requêtes SQL directement sur le fichier `Parquet` grâce à `DuckDB`

La deuxième approche permet de mettre en oeuvre des calculs plus efficaces
(`DuckDB`) est plus rapide mais nécessite un peu plus d'expertise sur la
manipulation de données, notamment des connaissances en SQL. 

Cette partie va fonctionner en trois temps:

1. Lecture des données `OpenFoodFacts` précédemment produites
2. Construction de statistiques descriptives standardisées
3. Construction de graphiques à partir de ces statistiques descriptives

Les étapes 1 et 2 sont séparées conceptuellement pour les parcours 🟡,🟢,🔵. 
Pour les parcours 🔴 et ⚫, l'utilisation de requêtes SQL fait que ces
deux étapes conceptuelles sont intriquées. Les parcours 🟡,🟢,🔵
peuvent observer les morceaux de code proposés dans le cadre 🔴 et ⚫,
c'est assez instructif. L'étape 3 (production de graphiques)
sera la même pour tous les parcours. 

::: {.cell .markdown}
```{=html}
<div class="alert alert-warning" role="alert" style="color: rgba(0,0,0,.8); background-color: white; margin-top: 1em; margin-bottom: 1em; margin:1.5625emauto; padding:0 .6rem .8rem!important;overflow:hidden; page-break-inside:avoid; border-radius:.25rem; box-shadow:0 .2rem .5rem rgba(0,0,0,.05),0 0 .05rem rgba(0,0,0,.1); transition:color .25s,background-color .25s,border-color .25s ; border-right: 1px solid #dee2e6 ; border-top: 1px solid #dee2e6 ; border-bottom: 1px solid #dee2e6 ; border-left:.2rem solid #ffc10780;">
<h3 class="alert-heading"><i class="fa fa-lightbulb-o"></i> Hint</h3>
```

Cette partie peut être faite sans avoir suivie la précédente. 
Il est alors recommandé d'effectuer deux actions:

1. Dans le fichier `config.yaml`, remplacer `"projet-funathon"` par votre nom
d'utilisateur sur le `SSP Cloud`
2. Créer une cellule en copiant-collant le texte suivant et
en remplacant `<USERNAME_SSPCLOUD>` par votre nom d'utilisateur sur le SSPCloud. 

```python
# créer une cellule de code et copier dedans ce texte
# remplacer `<USERNAME_SSPCLOUD>` par votre nom d'utilisateur sur le SSPCloud
!mc cp s3/projet-funathon/2023/sujet4/diffusion/openfood.parquet s3/<USERNAME_SSPCLOUD>/2023/sujet4/diffusion/openfood.parquet
```

⚠️ __Il faut avoir modifié la valeur de `USERNAME_SSPCLOUD` pour
que cette commande fonctionne__. 


Cette commande permet de copier le fichier d'exemple que nous avons
mis à disposition vers votre espace personnel.

```{=html}
</div>
```
:::


Nous proposons d'importer à nouveau nos configurations:

```{python}
from utils.import_yaml import import_yaml
config = import_yaml("config.yaml")
```

Les colonnes suivantes nous seront utiles dans cette partie:

```{python}
indices_synthetiques = [
    "nutriscore_grade", "ecoscore_grade", "nova_group"
]
principales_infos = ['product_name', 'code', 'preprocessed_labels', 'coicop']
```

Voici, à nouveau, la configuration pour permettre à `Python`
de communiquer avec l'espace de stockage distant:

```{python}
import s3fs

config = import_yaml("config.yaml")
INPUT_OPENFOOD = f"{config['BUCKET']}{config['DESTINATION_DATA_S3']}/openfood.parquet"

# Initialisation de la connexion
fs = s3fs.S3FileSystem(
    client_kwargs={"endpoint_url": config["ENDPOINT_S3"]}
)
```


## 2.2. Import des données depuis l'espace de stockage distant avec `Pandas` (🟡,🟢,🔵)

Il est recommandé pour les parcours 🟡, 🟢, 🔵 de travailler avec `Pandas` pour construire
des statistiques descriptives. Cela se fera en deux étapes:

- Import des données directement depuis l'espace de stockage, sans écriture intermédiaire sur le disque local,
puis nettoyage de celles-ci ;
- Construction de fonctions standardisées pour la production de statistiques descriptives.

### Import et nettoyage des données `OpenFoodFacts` (🟡, 🟢 et 🔵)

Il est possible de lire un CSV de plusieurs manières avec `Python`.
L'une d'elle se fait à travers le _[context manager](https://book.pythontips.com/en/latest/context_managers.html#context-managers)_. 
Le module `s3fs` permet d'utiliser ce _context manager_ pour lire un fichier distant, 
de manière très similaire à la lecture d'un fichier local. 

::: {.cell .markdown}
<!----- boite 🔵 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🔵", title = "Lire les données depuis un espace distant (🔵)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

A partir du _context manager_ intégré à `s3fs`, lire
les données en suivant les consignes suivantes:

- la localisation des données est stockée dans la variable `INPUT_OPENFOOD`
- Utiliser l'option `columns = principales_infos + indices_synthetiques`
pour n'importer que les variables nécessaires.

```{=html}
</details>
</div>
```

<!----- end 🔵 ----->
:::


::: {.cell .markdown}
<!----- boite 🟢 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🟢", title = "Lire les données depuis un espace distant (🟢)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Lors de l'écriture du fichier nous avons utilisé la commande suivante:

```python
# Ecriture au format parquet sur l'espace de stockage distant
with fs.open(DESTINATION_OPENFOOD, "wb") as file_location:
    openfood.to_parquet(file_location)
```

Nous proposons de suivre la même logique en changeant quelques éléments:

- La variable de chemin à utiliser ici est `INPUT_OPENFOOD` ;
- Le contexte n'est plus à l'écriture (_"wb"_) mais à la lecture (_"rb"_) ;
- La commande à exécuter dans ce contexte n'est plus l'écriture d'un fichier parquet
mais `pd.read_parquet`. Utiliser
l'option `columns = principales_infos + indices_synthetiques`
pour n'importer que les variables nécessaires.

```{=html}
</details>
</div>
```

<!----- end 🟢 ----->
:::


```{python}
#| classes: yellow-code
#| label: get-openfood-parquet-2
#| output: false

# Solution pour voie 🟡, 🟢 et 🔵
import pandas as pd

# methode 1: pandas
with fs.open(INPUT_OPENFOOD, "rb") as remote_file:
    openfood = pd.read_parquet(
        remote_file,
        columns = principales_infos + \
        indices_synthetiques
    )
```

Les données ont ainsi l'aspect suivant:

```{python}
openfood.head(2)
```

## 2.3. Statistiques descriptives (🟡, 🟢 et 🔵)

On désire calculer pour chaque classe de
produits - par exemple les boissons rafraichissantes - 
le nombre de produits qui partagent une même note pour chaque
indicateur de qualité nutritionnelle ou environnementale.

Nous allons utiliser le `DataFrame` suivant pour les calculs de notes:

```{python}
openfood_notes = openfood.loc[:,["coicop"] + indices_synthetiques]
```


::: {.cell .markdown}
<!----- boite 🔵 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🔵", title = "Distribution des notes par catégorie de produit (🔵)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

1. Pour chaque valeur de la variable `coicop`,
avec la méthode `agg`, effectuer un décompte des notes (`value_counts` en `Pandas`)
pour chaque variable de la liste `indices_synthetiques` grâce à la méthode `agg`.
Renommer ensuite les deux variables d'index 'coicop' et 'note' grâce à la méthode `reset_index`

2. Pivoter les données vers un format _long_
via les axes `coicop` et `note`

3. Dédupliquer les données en ne gardant que les paires uniques sur les variables
`variable, note, coicop`

```{=html}
</details>
</div>
```

<!----- end 🔵 ----->
:::


::: {.cell .markdown}
<!----- boite 🟢 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🟢", title = "Distribution des notes par catégorie de produit (🟢)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

1. Après un `groupby("coicop")`, effectuer un décompte des notes (`value_counts` en `Pandas`)
pour chaque variable de la liste `indices_synthetiques` grâce à la méthode `agg`
puis renommer les deux variables d'index 'coicop' et 'note' grâce à la méthode `reset_index`

```{=html}
<details>
<summary>Réponse en cas de difficulté</summary>
```

```python
stats_notes = (
    openfood_notes
    .groupby("coicop")
    .agg({i:'value_counts' for i in indices_synthetiques})
    .reset_index(names=['coicop', 'note'])
)
```

```{=html}
</details>

```

2. Utiliser `pd.melt` pour pivoter les données vers un format _long_
via les axes `coicop` et `note`

3. Dédupliquer les données en ne gardant que les paires uniques sur les variables
`variable, note, coicop` grâce à la méthode `drop_duplicates`

```{=html}
</details>
</div>
```

<!----- end 🟢 ----->
:::



```{python}
# Solution pour voie 🟡, 🟢 et 🔵
def compute_stats_grades(data, indices_synthetiques):
    stats_notes = (
        data
        .groupby("coicop")
        .agg({i:'value_counts' for i in indices_synthetiques})
        .reset_index(names=['coicop', 'note'])
    )
    stats_notes = pd.melt(stats_notes, id_vars = ['coicop','note'])
    stats_notes = stats_notes.dropna().drop_duplicates(subset = ['variable','note','coicop'])
    stats_notes['value'] = stats_notes['value'].astype(int)
  
    return stats_notes

stats_notes = compute_stats_grades(openfood_notes, indices_synthetiques)
```

## 2.4. Import et traitement des données avec `DuckDB` (🔴 et ⚫)

Cette partie propose pour les parcours 🔴 et ⚫ de reproduire l'analyse faite par
les parcours 🟡,🟢 et 🔵 via `Pandas`. 

`DuckDB` va être utilisé pour lire et agréger les données. 
Pour lire directement depuis un système de stockage distant, sans pré-télécharger les 
données, vous pouvez utiliser la configuration suivante de `DuckDB`:

```{python}
import duckdb
con = duckdb.connect(database=':memory:')
con.execute("""
    INSTALL httpfs;
    LOAD httpfs;
    SET s3_endpoint='minio.lab.sspcloud.fr'
""")
```

Et voici un exemple minimal de lecture de données à partir du chemin
`INPUT_OPENFOOD` défini précédemment. 

```{python}
duckdb_data = con.sql(
    f"SELECT product_name, preprocessed_labels, coicop, energy_100g FROM read_parquet('s3://{INPUT_OPENFOOD}') LIMIT 10"
)
duckdb_data.df() #conversion en pandas dataframe
```

Nous proposons de créer une unique requête SQL qui, dans une clause `SELECT`,
pour chaque classe de produit (notre variable de COICOP),
compte le nombre de produits qui partagent une même note. 


::: {.cell .markdown}
<!----- boite ⚫ ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "⚫", title = "Distribution des notes par catégorie de produit (⚫)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

- Créer une fonction `count_one_variable_sql` prenant un argument nommé `con` (connexion DuckDB),
un argument `variable` (par défaut égal à `nova_group`) et un chemin de lecture des données
dans le système `S3`. Cette fonction agrège calcule la statistique descriptive désirée 
pour `variable`.
- Créer le `DataFrame` qui combine toutes ces statistiques pour les
variables `["nutriscore_grade", "ecoscore_grade", "nova_group"]`.
Celui-ci comporte quatre variables: `coicop`, `note`, `value` et `variable`.

```{=html}
</details>
</div>
```

<!----- end ⚫ ----->
:::


::: {.cell .markdown}
<!----- boite 🔴 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🔴", title = "Distribution des notes par catégorie de produit (🔴)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Créer une fonction `count_one_variable_sql` prenant un argument nommé `con` (connexion DuckDB),
un argument `variable` (par défaut égal à `nova_group`) et un chemin de lecture des données
dans le système `S3`.

Cette fonction effectue les opérations suivantes:

- Créer un `DataFrame` `Pandas` après avoir agrégé les données via `DuckDB` grâce
au modèle de requête

```python
f"SELECT coicop, {variable} AS note, COUNT({variable}) AS value FROM read_parquet('s3://{path_within_s3}') GROUP BY coicop, {variable}"
```

- Crée une variable `variable` égale à la valeur de l'argument `variable`

- Créer le `DataFrame` qui combine toutes ces statistiques de la manière suivante
en appliquant la fonction de manière répétée :

```python
grades = ["nutriscore_grade", "ecoscore_grade", "nova_group"]
stats_notes_sql = [count_one_variable_sql(con, note, INPUT_OPENFOOD) for note in grades]
stats_notes_sql = pd.concat(stats_notes_sql)
```

```{=html}
</details>
</div>
```

<!----- end 🔴 ----->
:::

```{python}
# Solution à la voie 🔴 et ⚫ pour les curieux de la voie 🟡, 🟢 et 🔵
def count_one_variable_sql(con, variable, path_within_s3 = "temp.parquet"):
    query = f"SELECT coicop, {variable} AS note, COUNT({variable}) AS value FROM read_parquet('s3://{path_within_s3}') GROUP BY coicop, {variable}"
    stats_one_variable = con.sql(query).df().dropna()
    stats_one_variable['variable'] = variable
    stats_one_variable = stats_one_variable.replace('', 'NONE')

    return stats_one_variable

grades = ["nutriscore_grade", "ecoscore_grade", "nova_group"]
stats_notes_sql = [count_one_variable_sql(con, note, INPUT_OPENFOOD) for note in grades]
stats_notes_sql = pd.concat(stats_notes_sql)
```

Ceci nous donne donc le `DataFrame` suivant:

```{python}
stats_notes_sql.head(2)
```

## 2.5. Sauvegarde dans l'espace de stockage distant (🟡,🟢,🔵,🔴,⚫)

Ces statistiques descriptives sont à écrire dans l'espace de stockage
distant pour ne plus avoir à les calculer. 

```{python}
#| eval: false
def write_stats_to_s3(data, destination):
    # Ecriture au format parquet sur l'espace de stockage distant
    with fs.open(destination, "wb") as file_location:
        data.to_parquet(file_location)

write_stats_to_s3(stats_notes, f"{config['BUCKET']}{config['DESTINATION_DATA_S3']}/stats_notes_pandas.parquet")
write_stats_to_s3(stats_notes_sql, f"{config['BUCKET']}{config['DESTINATION_DATA_S3']}/stats_notes_sql.parquet")
```

⚠️ __Il faut avoir modifié la valeur de `BUCKET` dans le fichier `config.yaml` pour
que cette commande fonctionne__. 



## 2.6. Création d'un modèle de graphiques (🟡,🟢,🔵,🔴,⚫)

On va utiliser `Plotly` pour créer des graphiques et, ultérieurement,
les afficher sur notre page web. Cela permettra d'avoir un peu de
réactivité, c'est l'intérêt de faire un format _web_ plutôt qu'une
publication figée comme un `PDF`. 


::: {.cell .markdown}
<!----- boite ⚫ ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "⚫", title = "Modèle de figure pour les notes (⚫)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Créer une fonction standardisée dont l'_output_ est un objet `Plotly` 
respectant le cahier des charges suivant, pour chaque classe de produit : 

- Diagramme en barre présentant 
le nombre de produits ayant telle ou telle note
- Prévoir un argument pour mettre en surbrillance une valeur donnée
(par exemple la note `B`). 
- Prévoir un argument pour le titre du graphique

```{=html}
</details>
</div>
```

<!----- end ⚫ ----->
:::


::: {.cell .markdown}
<!----- boite 🔴 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🔴", title = "Modèle de figure pour les notes (🔴)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Créer une fonction standardisée dont les arguments sont

- Un jeu de données nommé `data`
- Une caractéristique nutritionnelle nommée `variable_note` par défaut égale à `nutriscore_grade`
- Une catégorie nommée `coicop`, par défaut égale à `01.1.7.3.2`
- Une note pour le produit dans une variable nommée `note_produit` par défaut égal à `B`
- Un titre par défaut égal à `Nutriscore`

Cette fonction effectue les tâches suivantes:

- Ne conserver, dans notre ensemble de valeurs agrégées, que celles relatives à la COICOP et
à la caractéristique nutritionnelle qu'on recherche ;
- Représenter sous forme de diagramme en barre les valeurs nutritionnelles pour chaque décile de la 
distribution avec, en rouge, celle de notre produit (`valeur_produit`)
- N'hésitez pas à utiliser les options de `Plotly` pour personnaliser la figure

```{=html}
</details>
</div>
```

<!----- end 🔴 ----->
:::

::: {.cell .markdown}
<!----- boite 🔵 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🔵", title = "Modèle de figure pour les notes (🔵)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Pour préparer cet exercice, créer les objets suivants:

```python
data = stats_nutritionnelles.copy()
variable_note = 'nutriscore_grade'
coicop = "01.1.7.3.2"
note_produit = "B"
titre = "Nutriscore"
```

1. Ne conserver que les observations où `data['variable']` est égale à la valeur `variable_note`
et où la variable `coicop` est égale à la valeur `coicop`. A l'issue de ces
filtres, nommer le dataframe obtenu `example_coicop`
2. Créer une 
colonne stockant les couleurs de notre graphique. Nommer cette variable `color`.
3. Créer un diagramme en barre avec:
        + sur l'axe des _x_ les quantiles
        + sur l'axe des _y_, la valeur à représenter
        + la couleur à partir de la variable `color`
        + Les _labels_ : pour l'axe des _x_ ne rien mettre et pour l'axe des _y_ : _"Note"_
        + Masquer la légende
        + Le titre à partir de la variable `titre` 
4. Encapsuler ce code dans une fonction nommée `figure_infos_notes` dont les arguments
sont les variables précédemment crées.

```{=html}
</details>
</div>
```

<!----- end 🔵 ----->
:::

::: {.cell .markdown}
<!----- boite 🟢 ----->

```{=html}
```{python}
#| echo: false
#| output: asis
#| eval: true
from utils_notebook import create_box_level
create_box_level(color = "🟢", title = "Modèle de figure pour les notes (🟢)")
```
<details>
<summary>Dérouler pour révéler les instructions</summary>
```

Pour préparer cet exercice, créer les objets suivants:

```python
data = stats_nutritionnelles.copy()
variable_note = 'nutriscore_grade'
coicop = "01.1.7.3.2"
note_produit = "B"
titre = "Nutriscore"
```

1. Utiliser la méthode [`loc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)
pour ne conserver que les observations où `data['variable']` est égale à la valeur `variable_note`
et où la variable `coicop` est égale à la valeur `coicop` (qu'on a fixé à `"01.1.7.3.2"`). A l'issue de ces
filtres, nommer le dataframe obtenu `example_coicop`
2. Utiliser [`np.where`](https://numpy.org/doc/stable/reference/generated/numpy.where.html) pour créer une 
colonne stockant les couleurs de notre graphique. On utilisera le rouge (_red_) lorsque la variable quantile
est égale à `note_produit` et du bleu (_royalblue_) sinon. Nommer cette variable `color`.
3. Créer un diagramme en barre avec:
        + sur l'axe des _x_ les notes (stockés dans la variable `note`)
        + sur l'axe des _y_, la valeur à représenter (stockée dans la variable `value`)
        + la couleur à partir de la variable `color`
        + Les _labels_ : pour l'axe des _x_ ne rien mettre et pour l'axe des _y_ : _"Note"_
        + Masquer la légende via l'argument `showlegend` de la méthode `update_layout` 
        + Le titre à partir de la variable `titre` 
4. Encapsuler ce code dans une fonction nommée `figure_infos_nutritionnelles` dont les arguments
sont `data`, `variable_nutritionnelle = 'nutriscore_grade'`, `coicop = "01.1.7.3.2"` et `valeur_produit = "B"`.

```{=html}
</details>
</div>
```

<!----- end 🟢 ----->
:::

Voici un exemple de fonction qui répond aux 
cahiers des charges ci-dessus:

```{python}
# Solution pour voie 🟡

import plotly.express as px
import numpy as np

def figure_infos_notes(
    data, variable_note = 'nutriscore_grade',
    coicop = "01.1.7.3.2", note_produit = "B",
    title = "Nutriscore"
):
    example_coicop = data.loc[data['variable'] == variable_note]
    example_coicop = example_coicop.loc[example_coicop['coicop']==coicop]
    example_coicop['color'] = np.where(example_coicop['note'] == note_produit, "Note du produit", "Autres produits")

    fig = px.bar(
        example_coicop,
        x='note', y='value', color = "color", template = "simple_white",
        title=title,
        color_discrete_map={"Note produit": "red", "Autres produits": "royalblue"},
        labels={
            "note": "Note",
            "value": ""
        }
    )
    fig.update_xaxes(
        categoryorder='array',
        categoryarray= ['A', 'B', 'C', 'D', 'E'])
    fig.update_layout(showlegend=False)
    fig.update_layout(hovermode="x")
    fig.update_traces(
        hovertemplate="<br>".join([
            "Note %{x}",
            f"{variable_note}: " +" %{y} produits"
        ])
    )

    return fig
```

Voici un exemple d'utilisation

```{python}
#| output: false
from utils.construct_figures import figure_infos_notes
fig = figure_infos_notes(stats_notes)
fig.update_layout(width=800, height=400)

fig
```

